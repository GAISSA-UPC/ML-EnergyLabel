{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfe3a385-35dd-4898-ad9c-8cbfb25ec82f",
   "metadata": {},
   "source": [
    "# Hugging Face Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9dc3ef52-80f1-4c1f-9bf7-a1b422c61a8e",
   "metadata": {},
   "source": [
    "The following script preprocess the resulting dataset from HFExtraction.ipynb. In particular we focus on feature engineering, variable standardization/harmonization, and one-hot encoding of tags. We create variables such as *co2_reported*, *auto*, *year_month*, and *domain* for filtering, splitting datasets, and analyzing model behavior across domains. To avoid memory overflow on the one-hot, we first splitted the dataset and one-hoted each split independently, concatenating the results afterwards.\n",
    "\n",
    "In order to execute the script ensure to run the cells in order. The script can take +5 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e48599-6e61-4794-9150-a456ef107b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6490c8",
   "metadata": {},
   "source": [
    "## Preprocessing of raw Hugging Face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d167e53-2ad9-40ae-ac87-235551236ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33761/4253178656.py:1: DtypeWarning: Columns (5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../../datasets/HFTotal.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../datasets/HFTotal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9fd48-f7dc-46ed-8778-32878a78c1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../../metadata/tags_metadata.yaml') as file:\n",
    "    tags_metadata = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81ee1df-17bb-4001-a8bc-f38925ae9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    if len(df) % 2 != 0:  # Handling `df` with `odd` number of rows\n",
    "        df = df.iloc[:-1, :]\n",
    "    df1, df2, df3, df4 =  np.array_split(df, 4)\n",
    "    return df1, df2, df3, df4\n",
    "\n",
    "def select_top_tags(df, n):\n",
    "    not_tags = [col for col in df.columns if not col.startswith('is_')]\n",
    "    tags_names = [col for col in df.columns if col.startswith('is_')]\n",
    "    relevant_tags = df[tags_names].sum(axis=0) > n\n",
    "    relevant_tags = [index for index, value in zip(relevant_tags.index, relevant_tags.values) if value]\n",
    "    df = df[not_tags + relevant_tags]\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_tags(df):\n",
    "    df_onehot = df.drop('tags', axis=1).join(\n",
    "        pd.get_dummies(\n",
    "            pd.DataFrame(df.tags.tolist(), df.index).stack(),\n",
    "            prefix='is', prefix_sep='_'\n",
    "        ).astype(int).groupby(level=0).sum()\n",
    "    )\n",
    "    return df_onehot\n",
    "\n",
    "\n",
    "def enlarge_tag_to_domain_dict(tag, tag_to_domain):\n",
    "    if 'gpt' in tag or 'bert' in NLP or 'bart' == tag or 't5' == tag:\n",
    "        tag_to_domain[tag] = 'NLP'\n",
    "    elif 'bert' in tag:\n",
    "        tag_to_domain[tag] = 'NLP'\n",
    "    \n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "    \n",
    "def assign_model_domain(tags, tags_to_domain):  \n",
    "    tags_to_domain = tags_to_domain['task_to_domain'] | tags_to_domain['model_to_domain'] | tags_to_domain['concepts_to_domain'] \n",
    "    model_domains = set()\n",
    "    tags_domain = set()\n",
    "    for tag in tags:\n",
    "        if tag in tags_to_domain:\n",
    "            model_domains.add(tags_to_domain[tag])\n",
    "            tags_domain.add(tag)\n",
    "    \n",
    "\n",
    "    if len(model_domains) == 0:\n",
    "        return None\n",
    "    \n",
    "    if len(model_domains) > 1:\n",
    "        if 'feature-extraction'in tags_domain:\n",
    "            if len(model_domains) == 2:\n",
    "                return 'NLP'\n",
    "        if 'Multimodal' in model_domains:\n",
    "            return 'Multimodal'\n",
    "        \n",
    "        return most_common(list(model_domains))\n",
    "    \n",
    "    return model_domains.pop()\n",
    "    \n",
    "    \n",
    "def filter_tags(tags, tags_metadata):\n",
    "    languages_list = tags_metadata['languages']\n",
    "    return [tag for tag in tags if tag not in languages_list and not tag.startswith(('license:', 'arxiv:', 'dataset:', 'doi:'))]\n",
    "    \n",
    "def tags_treatment(tags, tags_metadata):\n",
    "    tags = ast.literal_eval(tags) if not isinstance(tags, list) else tags\n",
    "    tags = filter_tags(tags, tags_metadata)\n",
    "    tags = ['no-tag'] if not tags else tags        \n",
    "    return [str(tag).lower().replace(' ', '-') for tag in tags]\n",
    "\n",
    "def set_library(library_name, tags, libraries_list):\n",
    "    libraries = [tag for tag in tags if tag in libraries_list]\n",
    "    library_name = list(set(libraries + [library_name])) if not isinstance(library_name, list) else list(set(libraries + library_name))\n",
    "    return [library for library in library_name if library is not None and not pd.isnull(library)]\n",
    "\n",
    "def set_language(tags, languages_list):\n",
    "    languages = [tag for tag in tags if tag in languages_list]\n",
    "    return list(set(languages))\n",
    "\n",
    "def set_license(tags, licenses_list):\n",
    "    licenses = [tag for tag in tags if tag in licenses_list]\n",
    "    return list(set(licenses))\n",
    "\n",
    "def concat_dataset_splits(df1,df2,df3,df4):\n",
    "    all_columns = set(df1.columns).union(df2.columns).union(df3.columns).union(df4.columns)\n",
    "\n",
    "    # Concatenate the DataFrames vertically with an outer join\n",
    "    df = pd.concat([df1, df2, df3, df4], axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "    # Find the non-shared columns\n",
    "    dfs = [df1, df2, df3, df4]\n",
    "    non_shared_columns = set()\n",
    "\n",
    "    for i, df1 in enumerate(dfs):\n",
    "        for df2 in dfs[i + 1:]:\n",
    "            non_shared_columns = non_shared_columns.union(set(df1.columns).symmetric_difference(df2.columns))\n",
    "\n",
    "    # Fill NaN values with zeros only for non-shared columns\n",
    "    for col in non_shared_columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def normalize_performance_metric(metric, metric_name):\n",
    "    if isinstance(metric, float):\n",
    "        if metric_name in ['f1', 'accuracy']:\n",
    "            if float(metric) > 1:\n",
    "                return float(metric)/100\n",
    "        return float(metric)\n",
    "        \n",
    "    if metric is None or pd.isnull(metric) or '[' in metric:\n",
    "        return None\n",
    "\n",
    "    if '%' in metric:\n",
    "        metric = float(metric.replace('%', ''))\n",
    "    elif ',' in metric:\n",
    "        metric = float(metric.replace(',', '.'))\n",
    "    elif isinstance(ast.literal_eval(metric), dict):\n",
    "        metric = float(ast.literal_eval(metric)[metric_name])\n",
    "    \n",
    "    if metric_name in ['f1', 'accuracy']:\n",
    "        if float(metric) > 1:\n",
    "            return float(metric)/100\n",
    "    if float(metric) > 1:\n",
    "        print(metric, metric_name)\n",
    "    return float(metric)\n",
    "\n",
    "\n",
    "def extract_context_info(text):\n",
    "    patterns = {\n",
    "        'hardware_type': r'[-*]*\\s*(?:hardware|Hardware)(?:\\s*[Tt]ype)*\\s*[:]+\\s*(.+)',\n",
    "        'hours_used': r'[-*]*\\s*Hours used\\s*[:]+\\s*(.+)',\n",
    "        'cloud_provider': r'[-*]*\\s*[Cc]loud [Pp]rovider\\s*[:]+\\s*(.+)',\n",
    "        'compute_region': r'[-*]*\\s*[Cc]ompute [Rr]egion\\s*[:]+\\s*(.+)',\n",
    "        'carbon_emitted': r'[-*]*\\s*[Cc]arbon [Ee]mitted\\s*[:]+\\s*(.+)',\n",
    "        'training_type': r'[-*]*\\s*(?:training|Training)(?:\\s*[Tt]ype)*\\s*[:]+\\s*(.+)',\n",
    "\n",
    "    }\n",
    "    \n",
    "    if text is None or pd.isnull(text):\n",
    "        return {'hardware_type':None, 'hours_used':None, 'cloud_provider':None, 'compute_region':None, 'carbon_emitted':None, 'training_type':None}\n",
    "    \n",
    "\n",
    "    results = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        regex = re.compile(pattern, re.IGNORECASE)\n",
    "        match = regex.search(text)\n",
    "        results[key] = match.group(1) if match else None\n",
    "\n",
    "    return results\n",
    "\n",
    "def context_metrics_treatment(df):\n",
    "    context_info_results = [extract_context_info(text) for text in df['modelcard_text']]\n",
    "    \n",
    "\n",
    "    null_phrases = ['Unknown', 'unknown', 'needed', 'Needed']\n",
    "    df['hardware_used'] = [context_info_results[idx]['hardware_type'] \n",
    "                           if pd.isnull(x) and all([phrase not in str(context_info_results[idx]['hardware_type']) for phrase in null_phrases]) else x \n",
    "                           for idx, x in enumerate(df['hardware_used'])] \n",
    "    df['geographical_location'] = [context_info_results[idx]['compute_region'] \n",
    "                                   if pd.isnull(x) and all([phrase not in str(context_info_results[idx]['compute_region']) for phrase in null_phrases]) else x \n",
    "                                   for idx, x in enumerate(df['geographical_location'])] \n",
    "    df['co2_eq_emissions'] = [context_info_results[idx]['carbon_emitted'] \n",
    "                              if pd.isnull(x) and all([phrase not in str(context_info_results[idx]['carbon_emitted']) for phrase in null_phrases]) else x \n",
    "                              for idx, x in enumerate(df['co2_eq_emissions'])] \n",
    "    df['hours_used'] = [context_dict['hours_used'] for context_dict in context_info_results]  \n",
    "    df['cloud_provider'] = [context_dict['cloud_provider'] for context_dict in context_info_results]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def performance_metrics_treatment(df):\n",
    "    df['f1'] = df['f1'].apply(lambda x: normalize_performance_metric(x, 'f1'))\n",
    "    df['accuracy'] = df['accuracy'].apply(lambda x: normalize_performance_metric(x, 'accuracy'))\n",
    "    df['rouge1'] = df['rouge1'].apply(lambda x: normalize_performance_metric(x, 'rouge1'))\n",
    "    df['rougeL'] = df['rougeL'].apply(lambda x: normalize_performance_metric(x, 'rougeL'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def harmonize_co2(co2):\n",
    "    \n",
    "    if isinstance(co2, float):\n",
    "        return co2\n",
    "    \n",
    "    if pd.isnull(co2):\n",
    "        return None\n",
    "    co2_found = re.match(r'\\d+\\.\\d+|\\d+', co2)\n",
    "\n",
    "    if co2_found is None:\n",
    "        return None\n",
    "    \n",
    "    return float(co2_found.group(0))\n",
    "\n",
    "\n",
    "def min_max_normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "def performance_score(df):\n",
    "    metrics = ['accuracy', 'f1', 'rouge1', 'rougeL']\n",
    "                                                                                                            \n",
    "    df['f1'] = min_max_normalize(df['f1'])\n",
    "    df['accuracy'] = min_max_normalize(df['accuracy'])\n",
    "    df['rouge1'] = min_max_normalize(df['rouge1'])\n",
    "    df['rougeL'] = min_max_normalize(df['rougeL'])\n",
    "    return df.apply(lambda row: stats.hmean([row[metric] for metric in metrics if not np.isnan(row[metric])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "002c2c04-e9e1-484b-a608-d25e524a13bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/.envs/RepositorioTFG/lib/python3.10/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/joel/.envs/RepositorioTFG/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df = performance_metrics_treatment(df)\n",
    "df = context_metrics_treatment(df)\n",
    "\n",
    "#Curation\n",
    "df['modelId'] = df['modelId'].apply(lambda x: x.split('/')[1] if len(x.split('/')) > 1 else x) #remove author from modelId\n",
    "df['co2_eq_emissions'] = df['co2_eq_emissions'].apply(lambda co2: harmonize_co2(co2)) #harmonize plenty of co2 values\n",
    "df['tags'] = df['tags'].apply(lambda tags: tags_treatment(tags, tags_metadata)) # filter and treat tags\n",
    "df['lastModified'] = pd.to_datetime(df['lastModified']) # convert the 'lastModified' column to datetime objects\n",
    "df['created_at'] = pd.to_datetime(df['created_at']) # convert the 'lastModified' column to datetime objects\n",
    "df['library_name'] = df.apply(lambda row: set_library(row['library_name'], row['tags'], tags_metadata['libraries']), axis=1) # adds libraries used by model\n",
    "df[\"datasets_size\"] = df[\"datasets_size\"].replace(0, np.nan)\n",
    "df = df[df['co2_eq_emissions'] != 0]\n",
    "\n",
    "\n",
    "#Feature Engineering\n",
    "df['co2_reported'] = df['co2_eq_emissions'].apply(lambda x: 0 if pd.isnull(x) or x is None else 1) \n",
    "df['license'] = df['tags'].apply(lambda tags: set_license(tags, tags_metadata['licenses']))\n",
    "df['language'] = df['tags'].apply(lambda tags: set_language(tags, tags_metadata['languages']))\n",
    "df['domain'] = df['tags'].apply(lambda tags: assign_model_domain(tags, tags_metadata['tags_to_domain']))\n",
    "df['year_month'] = df['created_at'].apply(lambda x: x.strftime('%Y-%m')) #  column 'year_month' to group the data monthly\n",
    "df['size_efficency'] = df['size'] / df['co2_eq_emissions']\n",
    "df['performance_score'] = performance_score(df)\n",
    "\n",
    "# we split, one hot and then combine splits to avoid memory overflow if we one-hot'ed with the whole dataset alltogether\n",
    "df1,df2,df3,df4 = split_df(df)\n",
    "df1,df2,df3,df4 = one_hot_tags(df1), one_hot_tags(df2), one_hot_tags(df3), one_hot_tags(df4)\n",
    "df1,df2,df3,df4 = select_top_tags(df1, 100), select_top_tags(df2, 100), select_top_tags(df3, 100), select_top_tags(df4, 100)\n",
    "df = concat_dataset_splits(df1,df2,df3,df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b2b85-1e47-41cc-acc7-972264f60891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../datasets/HFTotalProcessed.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc899082",
   "metadata": {},
   "source": [
    "## Preprocessing of CO2 data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0973dfb3",
   "metadata": {},
   "source": [
    "We join the co2 subset from the raw preprocessed data with the cleaned dataset and continue the preprocessing on the co2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb67be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34860/827070748.py:2: DtypeWarning: Columns (6,7,8,9,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../../datasets/HFTotalProcessed.csv')\n"
     ]
    }
   ],
   "source": [
    "def read_df_processed():\n",
    "    df = pd.read_csv('../../datasets/HFTotalProcessed.csv')\n",
    "    df = df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1)\n",
    "    df['library_name'] = df['library_name'].apply(lambda libraries:  ast.literal_eval(libraries) if not isinstance(libraries, list) else libraries)\n",
    "    df['datasets'] = df['datasets'].apply(lambda datasets: [''] if pd.isnull(datasets) else [datasets] if '[' not in datasets else ast.literal_eval(datasets))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = read_df_processed()\n",
    "\n",
    "def read_df_clean():\n",
    "    df = pd.read_csv('../../datasets/HFClean.csv')\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    df['library_name'] = df['library_name'].apply(lambda libraries:  ast.literal_eval(libraries) if not isinstance(libraries, list) else libraries)\n",
    "    df['datasets'] = df['datasets'].apply(lambda datasets: [''] if pd.isnull(datasets) else [datasets] if '[' not in datasets else ast.literal_eval(datasets))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_clean = read_df_clean()\n",
    "\n",
    "df = df[df['co2_reported'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82f43c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_columns = [col for col in df.columns if not col.startswith('is_')]\n",
    "df = df[wanted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4c2d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df\n",
    "df2 = df_clean\n",
    "\n",
    "# Merge the dataframes\n",
    "merged = df1.merge(df2, on='modelId', how='left', suffixes=('', '_y'))\n",
    "\n",
    "# Replace _x columns with _y columns (from HFClean.csv) when _y is not null\n",
    "for column in merged.columns:\n",
    "    if '_y' in column:\n",
    "        merged[column.replace('_y', '')] = merged[column].where(merged[column].notnull(), merged[column.replace('_y', '')])\n",
    "\n",
    "# Drop _y columns\n",
    "df = merged[df1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f38a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sources(source, auto):\n",
    "\n",
    "    if auto:\n",
    "        return 'AutoTrain'\n",
    "    if source == 'code carbon':\n",
    "        return 'Code Carbon'\n",
    "    if 'mlco2' in source or 'ML CO2' in source:\n",
    "        return 'MLCO2'\n",
    "    if 'BLOOM' in source:\n",
    "        return 'Article'\n",
    "    if 'Google Cloud' in source:\n",
    "        return 'Google Cloud Footprint'\n",
    "    \n",
    "    return 'Not Specified'\n",
    "\n",
    "def combine_location(location):\n",
    "\n",
    "    if 'East US' in location:\n",
    "        return 'East US'\n",
    "    if location == 'Frankfurt an Main, Germany (500-600 gCO2eq/kWh)':\n",
    "        return 'Frankfurt an Main, Germany'\n",
    "    return location\n",
    "\n",
    "\n",
    "def combine_training_type(training_type):\n",
    "\n",
    "    if 'fine' in training_type:\n",
    "        return 'fine-tuning'\n",
    "    if 'pre' in training_type:\n",
    "        return 'pretraining'\n",
    "    \n",
    "    return 'Not Specified'\n",
    "\n",
    "def create_performance_metrics(row):\n",
    "    return {'accuracy': row['accuracy'], 'f1': row['f1'], 'rouge1': row['rouge1'], 'rougeL': row['rougeL']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c86db99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['domain'] = df['domain'].fillna('Not Specified')\n",
    "df['training_type'] = df['training_type'].fillna('Not Specified')\n",
    "df['source'] = df['source'].fillna('Not Specified')\n",
    "df['geographical_location'] = df['geographical_location'].fillna('Not Specified')\n",
    "df['hardware_used'] = df['hardware_used'].fillna('Not Specified')\n",
    "\n",
    "df['source'] = df.apply(lambda row: combine_sources(row['source'], row['auto']), axis=1)\n",
    "df['geographical_location'] = df['geographical_location'].apply(lambda location: combine_location(location))\n",
    "df['training_type'] = df['training_type'].apply(lambda training_type: combine_training_type(training_type))\n",
    "df['size_efficency'] = df['size'] / df['co2_eq_emissions']\n",
    "df['datasets_size_efficency'] = df['datasets_size'] / df['co2_eq_emissions']\n",
    "df['downloads'] = df['downloads'].astype(int)\n",
    "df['likes'] = df['likes'].astype(int)\n",
    "df['co2_reported'] = df['co2_reported'].astype(int)\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['created_at'] = df['created_at'].dt.date\n",
    "df['performance_metrics'] = df.apply(create_performance_metrics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ba2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'hardware_used': 'environment'})\n",
    "wanted_columns = ['modelId', 'datasets', 'datasets_size', 'co2_eq_emissions', 'co2_reported', 'source', 'training_type', 'geographical_location', 'environment', 'performance_metrics', 'performance_score',\n",
    "                  'downloads', 'likes', 'library_name', 'domain', 'size', 'created_at', 'size_efficency', 'datasets_size_efficency']\n",
    "df = df[wanted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd8ffbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../datasets/HFCO2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
